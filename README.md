# Smart Connections MCP Server

A Model Context Protocol (MCP) server that provides semantic search and knowledge graph capabilities for Obsidian vaults using Smart Connections embeddings.

## Overview

This MCP server allows Claude (and other MCP clients) to:
- **Search semantically** through your Obsidian notes using pre-computed embeddings
- **Find similar notes** based on content similarity
- **Build connection graphs** showing how notes are related
- **Query by embedding vectors** for advanced use cases
- **Access note content** with block-level granularity

## Features

### ğŸ” Semantic Search
Uses the embeddings generated by Obsidian's Smart Connections plugin to perform fast, accurate semantic searches across your entire vault. Supports both:
- **Query-based search**: Uses Ollama to generate embeddings for search queries, enabling true semantic search
- **Keyword fallback**: Token-based matching when Ollama is unavailable

### ğŸ•¸ï¸ Connection Graphs
Builds multi-level connection graphs showing how notes are related through semantic similarity, helping discover hidden relationships in your knowledge base.

### ğŸ“Š Vector Similarity
Direct access to embedding-based similarity calculations using cosine similarity on 384-dimensional vectors (TaylorAI/bge-micro-v2 model).

### ğŸ“ Content Access
Retrieve full note content or specific sections/blocks with intelligent extraction based on Smart Connections block mappings.

## Installation

### Prerequisites

- Node.js 18 or higher
- An Obsidian vault with Smart Connections plugin installed and embeddings generated
- Claude Desktop (or another MCP client)
- **Optional**: Ollama with an embedding model for semantic query search (e.g., `nomic-embed-text-v2-moe`)

### Setup

1. **Clone the repository:**
   ```bash
   git clone https://github.com/msdanyg/smart-connections-mcp.git
   cd smart-connections-mcp
   ```

2. **Install dependencies:**
   ```bash
   npm install
   ```

3. **Build the TypeScript project:**
   ```bash
   npm run build
   ```

4. **Configure Claude Desktop:**

   Edit your Claude Desktop configuration file:
   - **macOS**: `~/Library/Application Support/Claude/claude_desktop_config.json`
   - **Windows**: `%APPDATA%\Claude\claude_desktop_config.json`

   Add the following to the `mcpServers` section:

    ```json
    {
      "mcpServers": {
        "smart-connections": {
          "command": "node",
          "args": [
            "/ABSOLUTE/PATH/TO/smart-connections-mcp/dist/index.js"
          ],
          "env": {
            "SMART_VAULT_PATH": "/ABSOLUTE/PATH/TO/YOUR/OBSIDIAN/VAULT",
            "OLLAMA_URL": "http://localhost:11434",
            "OLLAMA_MODEL": "nomic-embed-text-v2-moe:latest",
            "CACHE_DIR": "/ABSOLUTE/PATH/TO/.smart-env/query-cache"
          }
        }
      }
    }
    ```

    **Important**: Replace the paths with your actual paths:
    - Update the `args` path to point to your built `index.js` file
    - Update `SMART_VAULT_PATH` to your Obsidian vault path
    
    **Optional Ollama Configuration** (for semantic query search):
    - `OLLAMA_URL`: URL of your Ollama instance (default: `http://localhost:11434`)
    - `OLLAMA_MODEL`: Embedding model to use (must match your vault embeddings)
    - `CACHE_DIR`: Directory for query embedding cache (improves performance)

5. **Optional: Setup Ollama for Semantic Query Search**

   To enable true semantic search for text queries (recommended):

   ```bash
   # Install Ollama (if not already installed)
   # Visit: https://ollama.ai
   
   # Pull the embedding model that matches your vault
   # For nomic embeddings (768 dimensions):
   ollama pull nomic-embed-text-v2-moe:latest
   
   # For default Smart Connections (384 dimensions):
   ollama pull TaylorAI/bge-micro-v2
   
   # Start Ollama (usually runs automatically)
   ollama serve
   ```

   Without Ollama, the server will fall back to keyword-based search (less accurate).

6. **Restart Claude Desktop**

   The MCP server will automatically start when Claude Desktop launches.

## Available Tools

### 1. `get_similar_notes`

Find notes semantically similar to a given note.

**Parameters:**
- `note_path` (string, required): Path to the note (e.g., "Note.md" or "Folder/Note.md")
- `threshold` (number, optional): Similarity threshold 0-1, default 0.5
- `limit` (number, optional): Maximum results, default 10

**Example:**
```typescript
{
  "note_path": "MyNote.md",
  "threshold": 0.7,
  "limit": 5
}
```

**Returns:**
```json
[
  {
    "path": "RelatedNote.md",
    "similarity": 0.85,
    "blocks": ["#Overview", "#Key Points", "#Details"]
  }
]
```

### 2. `get_connection_graph`

Build a multi-level connection graph showing how notes are semantically connected.

**Parameters:**
- `note_path` (string, required): Starting note path
- `depth` (number, optional): Graph depth (levels), default 2
- `threshold` (number, optional): Similarity threshold 0-1, default 0.6
- `max_per_level` (number, optional): Max connections per level, default 5

**Example:**
```typescript
{
  "note_path": "MyNote.md",
  "depth": 2,
  "threshold": 0.7
}
```

**Returns:**
```json
{
  "path": "MyNote.md",
  "depth": 0,
  "similarity": 1.0,
  "connections": [
    {
      "path": "RelatedNote.md",
      "depth": 1,
      "similarity": 0.82,
      "connections": [...]
    }
  ]
}
```

### 3. `search_notes`

Search notes using a text query. Uses semantic search via Ollama if available, falls back to keyword matching otherwise.

**Parameters:**
- `query` (string, required): Search query text
- `limit` (number, optional): Maximum results, default 10
- `threshold` (number, optional): Similarity threshold 0-1, default 0.5

**Example:**
```typescript
{
  "query": "project management",
  "limit": 5
}
```

**How it works:**
1. **With Ollama**: Generates query embedding â†’ cosine similarity search (cached for performance)
2. **Without Ollama**: Token-based keyword matching (less accurate but functional)

**Returns:**
```json
[
  {
    "path": "ProjectNote.md",
    "similarity": 0.78,
    "blocks": ["#Overview", "#Timeline"]
  }
]
```

### 4. `get_embedding_neighbors`

Find nearest neighbors for a given embedding vector (advanced use).

**Parameters:**
- `embedding_vector` (number[], required): 384-dimensional vector
- `k` (number, optional): Number of neighbors, default 10
- `threshold` (number, optional): Similarity threshold 0-1, default 0.5

### 5. `get_note_content`

Retrieve full note content with optional block extraction.

**Parameters:**
- `note_path` (string, required): Path to the note
- `include_blocks` (string[], optional): Specific block headings to extract

**Example:**
```typescript
{
  "note_path": "MyNote.md",
  "include_blocks": ["#Introduction", "#Main Points"]
}
```

**Returns:**
```json
{
  "content": "# Full note content...",
  "blocks": {
    "#Introduction": "Content of this section...",
    "#Main Points": "Content of this section..."
  }
}
```

### 6. `get_stats`

Get statistics about the knowledge base.

**Parameters:** None

**Returns:**
```json
{
  "totalNotes": 137,
  "totalBlocks": 1842,
  "embeddingDimension": 384,
  "modelKey": "TaylorAI/bge-micro-v2"
}
```

## Usage Examples

Once configured, you can ask Claude to use these tools naturally:

- **"Find notes similar to my project planning document"**
- **"Show me a connection graph starting from my main research note"**
- **"Search my notes for information about [your topic]"**
- **"What's in my note about [topic]?"**
- **"Give me stats about my knowledge base"**

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Claude Desktop                         â”‚
â”‚                    (MCP Client)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â”‚ MCP Protocol (stdio)
                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Smart Connections MCP Server                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  index.ts (MCP Server + Tool Handlers)             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                   â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  search-engine.ts (Semantic Search Logic)          â”‚   â”‚
â”‚  â”‚  - getSimilarNotes()                               â”‚   â”‚
â”‚  â”‚  - getConnectionGraph()                            â”‚   â”‚
â”‚  â”‚  - searchByQuery() â†’ searchByEmbedding()           â”‚   â”‚
â”‚  â”‚  - searchByKeyword() (fallback)                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚               â”‚                       â”‚                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  ollama-client.ts           â”‚  â”‚  embedding-utils.ts â”‚  â”‚
â”‚  â”‚  - Generate query embeddingsâ”‚  â”‚  - cosineSimilarity â”‚  â”‚
â”‚  â”‚  - Disk-based LRU cache     â”‚  â”‚  - findNeighbors    â”‚  â”‚
â”‚  â”‚  - Health check & fallback  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚               â”‚                                             â”‚
â”‚               â”‚ HTTP                                        â”‚
â”‚               â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  smart-connections-loader.ts (Data Access)         â”‚   â”‚
â”‚  â”‚  - Load .smart-env/smart_env.json                  â”‚   â”‚
â”‚  â”‚  - Load .smart-env/multi/*.ajson embeddings        â”‚   â”‚
â”‚  â”‚  - Read note content from vault                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚               â”‚               â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Ollama  â”‚  â”‚ File System   â”‚  â”‚ .smart-env/          â”‚
â”‚  Server  â”‚  â”‚ (vault *.md)  â”‚  â”‚ query-cache/         â”‚
â”‚  :11434  â”‚  â”‚               â”‚  â”‚ embeddings.json      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Technical Details

### Embedding Models

The server supports multiple embedding models depending on your Smart Connections configuration:

| Model                         | Dimensions | Notes                                    |
|-------------------------------|------------|------------------------------------------|
| TaylorAI/bge-micro-v2         | 384        | Default Smart Connections model          |
| nomic-embed-text-v2-moe       | 768        | Higher quality, recommended for Ollama   |
| Custom models                 | Variable   | Auto-detected from vault embeddings      |

**Important**: Your `OLLAMA_MODEL` must match the embedding model used in your Obsidian vault.

### Data Format
The server reads from Obsidian's Smart Connections `.smart-env/` directory:
- `smart_env.json`: Configuration and model settings
- `multi/*.ajson`: Per-note embeddings and block mappings
- `query-cache/embeddings.json`: Cached query embeddings (auto-created)

### Performance

| Operation          | With Ollama Cache | Without Cache | Keyword Fallback |
|--------------------|-------------------|---------------|------------------|
| Load time          | 2-5s             | 2-5s          | 2-5s             |
| First query search | ~500-800ms       | ~500-800ms    | ~100-200ms       |
| Cached query       | <50ms            | N/A           | ~100-200ms       |
| Memory usage       | ~30-40MB         | ~20-30MB      | ~20-30MB         |

**Query Cache Benefits:**
- LRU eviction (max 1000 entries)
- Disk-persisted across restarts
- Significantly faster repeated searches
- Automatic cleanup of old entries

### Similarity Metric
- **Cosine similarity** for all vector comparisons
- Range: 0.0 (unrelated) to 1.0 (identical)
- Configurable threshold per query

## Development

### Build
```bash
npm run build
```

### Watch Mode
```bash
npm run watch
```

### Run Locally
```bash
export SMART_VAULT_PATH="/path/to/your/vault"
npm run dev
```

### Project Structure
```
smart-connections-mcp/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.ts                    # MCP server & tool handlers
â”‚   â”œâ”€â”€ search-engine.ts            # Semantic search logic (async)
â”‚   â”œâ”€â”€ ollama-client.ts            # Ollama integration & caching (NEW)
â”‚   â”œâ”€â”€ smart-connections-loader.ts # Data loading
â”‚   â”œâ”€â”€ embedding-utils.ts          # Vector math utilities
â”‚   â””â”€â”€ types.ts                    # TypeScript type definitions
â”œâ”€â”€ dist/                           # Compiled JavaScript (generated)
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â””â”€â”€ README.md
```

## Troubleshooting

### "Smart Connections directory not found"
- Ensure your vault has the Smart Connections plugin installed
- Verify embeddings have been generated (check `.smart-env/multi/` directory)
- Check that `SMART_VAULT_PATH` points to the correct vault

### "Configuration file not found"
- Run Smart Connections in Obsidian at least once to generate configuration
- Check for `.smart-env/smart_env.json` in your vault

### "No embeddings found for note"
- Some notes may not have embeddings if they're too short (< 200 chars)
- Re-run Smart Connections embedding generation in Obsidian

### Server not appearing in Claude Desktop
- Verify the configuration file syntax (JSON must be valid)
- Check the file paths are absolute paths, not relative
- Restart Claude Desktop completely
- Check Claude Desktop logs for error messages

### Ollama-related issues

#### "Ollama unavailable, using keyword fallback"
- **Normal behavior** - server continues to work with keyword matching
- To enable semantic search:
  1. Install Ollama: https://ollama.ai
  2. Pull embedding model: `ollama pull nomic-embed-text-v2-moe`
  3. Verify Ollama is running: `curl http://localhost:11434/api/tags`
  4. Restart Claude Desktop

#### "Embedding dimension mismatch"
- Your `OLLAMA_MODEL` doesn't match your vault embeddings
- Check your vault's model: Look in `.smart-env/smart_env.json` â†’ `"embed_model"`
- Update `OLLAMA_MODEL` in your MCP configuration to match
- Common combinations:
  - Vault uses `TaylorAI/bge-micro-v2` â†’ Ollama model: `TaylorAI/bge-micro-v2`
  - Vault uses `nomic-embed-text-v2-moe` â†’ Ollama model: `nomic-embed-text-v2-moe:latest`

#### Slow query performance
- First queries are slower (~500-800ms) while building cache
- Subsequent identical queries should be <50ms
- Check cache file exists: `.smart-env/query-cache/embeddings.json`
- Cache is LRU with max 1000 entries - old entries auto-removed

## License

MIT

## Author

Daniel Glickman

## Acknowledgments

- Built for use with [Obsidian](https://obsidian.md/)
- Integrates with [Smart Connections](https://github.com/brianpetro/obsidian-smart-connections) plugin
- Uses [Model Context Protocol](https://modelcontextprotocol.io/) by Anthropic
